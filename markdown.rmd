---
title: "Trabalho Pratico 3 Metodos econometricos"
author: "Grupo 9"
date: "31 de outubro de 2022"
output:
  html_document: default
  pdf_document:
    keep_tex: yes
  word_document: default
editor_options:
  markdown:
    wrap: 72

---

** Relatorio Grupo 9 **

Tema: *relat√≥rio completo sobre investimento em empresas estatais*

## Quest√£o 0 - Iniciando arquivos e dados

```{r}
library(AER)
library(strucchange)
library(fBasics)
library(quantreg)
library(quantmod)
library(tseries)
library(stargazer)

data <- read.table('ArquivoExercicio3.csv',sep=';',dec='.',header = T)
```
## Quest√£o 1
A partir dos dados brutos, construa os seguintes indicadores e inclua-os no dataframe original.
Em seguida, gere o resumo estat√≠stico da base de dados Dica: se usar o comando base$X<-y, √© criada
uma nova coluna na tabela com nome de X contendo a vari√°vel y.
a) Book-to-Market= ùëÉùêø/ùëâùëéùëôùëúùëüùëÄùëíùëüùëêùëéùëëùëú com nome de BtM
b) Rela√ß√£o PL e Passivo = ùëÉùêø/ùëÉùëéùë†ùë†ùëñùë£ùëú com nome de RPLP
c) ROA = ùêøùêø / ùê¥ùë°ùëñùë£ùëúùëáùëúùë°ùëéùëô com nome de ROA
d) ROE= ùêøùêø /ùëÉùêø com nome de ROE
```{r}
data$BtM <- data$PL / data$ValorMercado
data$RPLP <- data$PL / data$Passivo
data$ROA <- data$LL / data$AtivoTotal
data$ROE <- data$LL / data$PL
summary(data)
```
## Quest√£o 2
Estime o modelo de regress√£o m√∫ltipla a seguir e analise os coeficientes, R^2, R^2 ajustado e o Teste F:
Divùëñ = ùõº + ùõΩ1BtMùëñ + ùõΩ2RPLPùëñ + ùõΩ3ROAùëñ + ùõΩ4ROEùëñ + ùõΩ5AtivoTotal
```{r}
reg <- lm(Div ~ BtM + RPLP + ROA + ROE + AtivoTotal, data = data)
summary(reg)
```
O modelo de regress√£o m√∫ltipla da quest√£o possui um R2 de valor num√©rico de 0,7899. Isso significa que 78,99% da vari√°vel dependente Y pode ser explicada pelas vari√°veis independentes do modelo. Al√©m disso, o modelo possui um R2 ajustado de valor num√©rico de 0,7764. Isso significa que, ao comparar esse modelo com algum outro modelo semelhante, o nosso modelo inicial descrever√° melhor a vari√°vel dependente Y do que o segundo modelo da compara√ß√£o caso esse segundo modelo tenha um R2 ajustado inferior √† 0,7764. Vale lembrar que o R2 ajustado √© ajustado pelos graus de liberdade do modelo. Por fim, o teste F do modelo tem valor num√©rico de 58,64, o que √© um valor consideravelmente alto. Mas, para conseguir fazer a an√°lise completa do teste F, temos que olhar tamb√©m para o P-valor do modelo, que √© infinitamente pequeno. Desse modo, com a estat√≠stica F alta e o P-valor baixo, podemos rejeitar a hip√≥tese nula que afirma que o modelo restrito √© o melhor e aceitar o modelo irrestrito.

## Quest√£o 3
Calcule e analise o Fator da Infla√ß√£o da Vari√¢ncia e a matriz de covari√¢ncia dos coeficientes
do modelo estimado. Analise os resultados e conclua sobre a adequabilidade da modelagem.
```{r}
vif(reg)
vcov(reg)
```
A priori, o fator de infla√ß√£o da vari√¢ncia (VIF) √© uma maneira de medir a multicolinearidade, que avalia o quanto a vari√¢ncia de um coeficiente de regress√£o estimado aumenta se as suas preditoras estiverem correlacionadas. Se nenhum fator estiver correlacionado, os VIFs ser√£o todos 1. Se o VIF for igual a 1 n√£o h√° multicolinearidade entre os fatores, mas se o VIF for maior que 1, as preditoras podem estar moderadamente correlacionadas. A sa√≠da abaixo mostra que o VIF para os fatores de BtM, Ativo total e RPLP  s√£o menores que 1.5, o que indica alguma correla√ß√£o, mas n√£o o suficiente para se preocupar demais com isso. Isso porque um VIF entre 5 e 10 que indica alta correla√ß√£o, o que pode ser problem√°tico. E se o VIF for acima de 10, segundo Draper e Smith (1998), pode-se assumir que os coeficientes de regress√£o est√£o mal estimados devido √† multicolinearidade. Logo, os demais fatores, ROA e ROE, est√£o entre 4,6 e 5, isto √©, apresentam m√©dia-alta correla√ß√£o.

## Quest√£o 4
Reestime o modelo retirando o ROA e analise o Fator da Infla√ß√£o da Vari√¢ncia e a matriz de
covari√¢ncia dos coeficientes do modelo estimado. Ademais, realize o teste ANOVA para comparar
os dois modelos, sendo este modelo sem a vari√°vel ROA o modelo restrito.
```{r}
reg2 <- lm(Div ~ BtM + RPLP + ROE + AtivoTotal, data = data)

vif(reg2)
vcov(reg2)
anova(reg,reg2)
```
Retirando o ROA e analisando novamente o Fator da Infla√ß√£o da Vari√¢ncia e a matriz de covari√¢ncia dos coeficientes do modelo estimado, nota-se que todos os fatores apresentaram VIF menor que 1,5, logo, indica alguma correla√ß√£o, mas n√£o o suficiente para se preocupar com o problema da multicolinearidade. Dessa forma, √© menos prov√°vel que haja s√©rios problemas na estima√ß√£o dos coeficientes de regress√£o. Ademais, realizou-se o teste ANOVA, considerando o modelo sem a vari√°vel ROA o modelo restrito, em que se testa a hip√≥tese de que a m√©dia de dois ou mais fatores s√£o iguais. Notem que o p-valor estimado foi igual √† 0,4573 (Pr(>F)), ou seja, estatisticamente igual a zero, isto nos leva a n√£o rejeitar a hip√≥tese nula que afirma que as m√©dias s√£o todas iguais.

## Quest√£o 5
Analise os coeficientes, o R^2 Ajustado e a estat√≠stica F do modelo.
```{r}
summary(reg2)
```
Este modelo possui um R2 de valor num√©rico de 0,7884, o que indica que 78,84% da vari√°vel dependente √© explicada pelas vari√°veis explicativas do modelo. Em rela√ß√£o ao R2 ajustado, esse coeficiente tem valor num√©rico de 0,7776, o que significa que, quando comparado a um outro modelo, ele ser√° o escolhido, caso o R2 ajustado do segundo modelo for inferior a este valor. Agora, caso o R2 ajustado do segundo modelo for superior √† 0,7776, ele explicar√° melhor a vari√°vel dependente. Por fim, o teste F do modelo tem estat√≠stica equivalente √† 73,57, enquanto o P-valor do modelo (estat√≠stica tamb√©m necess√°ria para avaliar o teste F) vale um n√∫mero infinitamente pequeno. Desse modo, pode-se rejeitar a hip√≥tese nula que afirma que o modelo restrito √© o melhor e aceitar o modelo irrestrito.
## Quest√£o 6
Crie o gr√°fico de dispers√£o, histograma e o gr√°fico quantil-quantil dos res√≠duos da regress√£o.
Analise os gr√°ficos gerados.
```{r}
par(mfrow=c(2, 2))
plot(reg2$residuals)
hist(reg2$residuals)
qqPlot(reg2$residuals)
```
A priori, os gr√°ficos de dispers√£o de cada vari√°vel explicativa contra a vari√°vel resposta permite verificar, preliminarmente, tend√™ncias e valores at√≠picos. Assim √© poss√≠vel visualizar tais fatores para os res√≠duos da regress√£o e notar a presen√ßa de alguns outliers (valores at√≠picos que n√£o seguem a linha tendenciosa expl√≠cita no gr√°fico). Ademais, em rela√ß√£o ao histograma, outro tipo de gr√°fico utilizado com a finalidade de analisar tais tend√™ncias frequentistas, √© visualmente not√°vel que a frequ√™ncia mais evidente e recorrente do res√≠duo de regress√£o √© localizada no fator 0e +00 (assim como no primeiro gr√°fico). No √∫ltimo gr√°fico, o gr√°fico quantil-quantil, √© poss√≠vel notar, a partir da declividade da curva azulada, a linha de tend√™ncia, que majoritariamente se localiza no fator 0e+00 mas, como dito anteriormente, apresenta a declividade e alguns outliers, demonstrando que n√£o segue uma 100% retil√≠nea.
## Quest√£o 7
Realize e analise os seguintes testes de normalidade nos res√≠duos da regress√£o, citando a H0 e
H1 de cada um:
a) Teste de Shapiro
b) Teste Jarque-Bera
c) Teste de Breusch-Pagan
d) Teste de Durbin-Watson
```{r}
shapiro.test(reg2$residuals)
jarque.bera.test(reg2$residuals)
bptest(reg2)
dwtest(reg2)
```
O teste de Shapiro √© utilizado para avaliar se a distribui√ß√£o dos residos √© semelhante a uma distribui√ß√£o normal. Desse modo, a sua hip√≥tese nula (H0) seria: a distribui√ß√£o √© semelhante a uma distribui√ß√£o normal e a sua hip√≥tese alternativa  (H1) seria: a distribui√ß√£o n√£o √© semelhante a uma distribui√ß√£o normal. No caso estimado, como o P-valor do modelo √© muito baixo, h√° uma chance muito pequena de se rejeitar a hip√≥tese nula e estar errado, logo, aceitamos a hip√≥tese nula proposta.
O teste Jarque-Bera, por sua vez, √© utilizado para testar a normalidade do modelo, ou seja, se o modelo pertence ou n√£o √† uma distribui√ß√£o normal. Dessa forma, a hip√≥tese nula (H0) seria: y1, y2, . . . , yn ‚àº N(¬µ, œÉ2 ) enquanto a hip√≥tese alternativa seria que o modelo n√£o pertence √† uma distribui√ß√£o normal. No caso do nosso modelo testado, como o P-valor tamb√©m √© muito baixo, a hip√≥tese nula n√£o √© rejeitada.
O teste de Breusch-Pagan testa a heterocedasticidade do modelo. Ou seja, ele testa se o modelo apresenta  vari√¢ncias do termo de perturba√ß√£o n√£o iguais para todas as observa√ß√µes. Desse modo, a hip√≥tese nula (H0) ser√° que as vari√¢ncias s√£o diferentes nas observa√ß√µes e a hip√≥tese alternativa (H1) ser√° que as vari√¢ncias n√£o s√£o diferentes. Desse modo,  como o P-valor √© infinitamente baixo, a hip√≥tese nula n√£o √© rejeitada.
O teste de Durbin-Watson testa a presen√ßa de autocorrela√ß√£o entre os erros do modelo. Ou seja, ele testa se os erros das observa√ß√µes s√£o correlacionados ou n√£o. Desse modo, a sua hip√≥tese nula (H0) ser√° que os erros s√£o correlacionados enquanto a hip√≥tese alternativa (H1) ser√° que esses erros n√£o s√£o correlacionados. Pelo resultado do nosso teste, como o P-valor √© alto (0,3524) n√≥s rejeitamos a nossa hip√≥tese nula e aceitamos a hip√≥tese alternativa, em que os erros do modelo n√£o est√£o correlacionados.
## Quest√£o 8
Realize os testes de heterocedasticidade (White e Breusch-Pagan) para verificar a
heterocedasticidade nos res√≠duos do modelo e analise o resultado dos mesmos.7
```{r}
paste("----- TESTE BP -----")
bptest(reg2)
reg3 <- lm(Div ~
             BtM * RPLP +
               BtM * ROE +
               BtM * AtivoTotal +
               RPLP * ROE +
               ROE * AtivoTotal
               + I(AtivoTotal^2) + I(BtM^2)
               + I(RPLP^2) + I(ROE^2), data = data)
paste("----- TESTE WHITE -----")
bptest(reg3)
```
A priori, √© importante diferenciar o conceito de homocedasticidade e heterocedasticidade. Desse modo, respectivamente, o primeiro conceito afirma que a vari√¢ncia dos erros E, condicionada aos valores das vari√°veis explanat√≥rias, ser√° constante. Em contrapartida, na heterocedasticidade,  a vari√¢ncia dos erros ser√° diferente para cada valor condicional de Xj. Assim, na presen√ßa de heterocedasticidade dos erros, os estimadores de MQO continuam sendo n√£o viesados e consistentes, mas deixam de ser eficientes (ou seja, n√£o possuem mais vari√¢ncia m√≠nima). Outra importante consequ√™ncia da heterocedasticidade √© o vi√©s do estimador da vari√¢ncia de beta, mesmo para amostras grandes (inconsist√™ncia). Como resultado, as estat√≠sticas de teste t e F deixam de ser v√°lidas, pois dependem da vari√¢ncia do estimador. Assim, duas formas de identificar a heterocedasticidade s√£o os testes estat√≠sticos: Teste de Breusch-Pagan e o Teste de White. Logo, analisando as sa√≠das do R a seguir, nota-se que, em ambos os testes o p-valor √© n√£o significativo (<5%). Dessa forma, a probabilidade de erro ao rejeitar H0 √© menor que 0,05. Em outras palavras, h√° fort√≠ssimas evid√™ncias para afirmarmos que os erros s√£o heteroced√°sticos pois ao fazermos tal afirma√ß√£o estar√≠amos sujeitos a uma chance de erro menores que 0,05.
## Quest√£o 9
Realize o teste RESET para verificar problemas de forma funcional no modelo e analise o
resultado do teste. Conclua sobre a valida√ß√£o do modelo estimado.
```{r}
reset(reg2)
```
Uma vez que o p-valor n√£o atinge o n√≠vel de signific√¢ncia, sendo ele 0,05, e o p-valor ter apenas 0,0017, o modelo deve ser considerado. Assim, podemos descartar a hip√≥tese nula de que um modelo com potencias √© melhor do que o modelo proprio, ou seja, o modelo pr√≥prio sem pot√™ncias √© melhor que o modelo com pot√™ncias.
## Quest√£o 10
Estime a matriz de covari√¢ncia com erros padr√£o de White e o valor dos coeficientes corrigidos.
Dica: procure sobre a fun√ß√£o ‚Äúcoeftest‚Äù.
```{r}
vcovHC(reg2)
vcov(reg2)
```
## Quest√£o 11
Estime o modelo de regress√£o m√∫ltipla a seguir e analise os coeficientes, R2, R2 ajustado e o Teste F:
log(Divùëñ) = ùõº + ùõΩ1BtMùëñ + ùõΩ2RPLPùëñ + ùõΩ3ROEùëñ + ùõΩ4log(AtivoTotalùëñ )
```{r}
reg4 <- lm(log(Div) ~ BtM + RPLP + ROE + log(AtivoTotal), data = data)
summary(reg4)
```
O modelo possui um R2 igual a 0,9737, o que significa que 97,37% da vari√°vel dependente Y √© explicada pelas vari√°veis independentes explicativas. J√° o R2 ajustado do modelo vale 0,9723, o que significa que, ao compar√°-lo com algum outro modelo, o modelo inicial ser√° o escolhido se o R2 ajustado do segundo modelo for menor que 0,9737. √â bom ressaltar que o R2 ajustado √© ajustado pelos graus de liberdade do modelo. Por fim, o teste F do modelo tem estat√≠stica igual √† 730.3, e o P-valor do modelo corresponde a um n√∫mero infinitamente pequeno. Desse modo, pode-se rejeitar a hip√≥tese nula que afirma que o modelo restrito √© o melhor e aceitar o modelo irrestrito.
## Quest√£o 12
Refa√ßa os testes propostos nas quest√µes 7,8 e 9. Conclua sobre a validade da modelagem e os
efeitos da reespecifica√ß√£o do modelo.
```{r}
paste("--- Teste de Shapiro ---")
shapiro.test(reg4$residuals)
paste("--- Teste Jarque-Bera ---")
jarque.bera.test(reg4$residuals)
paste("--- Teste de Breusch-Pagan ---")
bptest(reg4)
paste("--- Teste de Durbin-Watson ---")
dwtest(reg4)
reg4White <- lm(log(Div) ~
             BtM * RPLP +
               BtM * ROE +
               BtM * log(AtivoTotal) +
               RPLP * ROE +
               ROE * log(AtivoTotal)
               + I(log(AtivoTotal)^2) + I(BtM^2)
               + I(RPLP^2) + I(ROE^2), data = data)
paste("--- Teste de White ---")
bptest(reg4White)
paste('--- Teste Reset ---')
reset(reg4)
```
Para o referente aos testes da quest√£o 7, todos os testes refeitos com o novo modelo tiveram um p-valor significativo, em contra-partida dos feitos anteriormente que o tinham abaixo do n√≠vel de signific√¢ncia. Sendo que para os testes Shapiro-Wilk, Jarque-Bera, Breusch-Pagan, e Durbin-Watson, os valores foram do p-valor foram respectivamente: 0,2978; 0,3339; 0,1093; 0,1288. Para o modelo de Shapiro-Wilk isso ir√° significar que a distribui√ß√£o do erro n√£o se aproxima de uma distribui√ß√£o normal. Enquanto isso, para o modelo de Jarque-Bera isso ir√° significar que a distribui√ß√£o n√£o se aproxima de uma distribui√ß√£o normal . J√° para o teste Breusch-Pagan, que testa se o modelo apresenta vari√¢ncias do termo de perturba√ß√£o n√£o iguais para todas as observa√ß√µes, ao obter um p-valor alto, essa hip√≥tese √© rejeitada. Ainda, para Durbin- Watson que testa a presen√ßa de autocorrela√ß√£o entre os erros do modelo, por obter um p-valor alto, essa hip√≥tese √© rejeitada.
J√° para o que refere aos testes presentes na quest√£o 8, os testes de heterocedasticidade, White e Breusch-Pagan, no caso da refeita do teste White com o novo modelo o p-valor ser√° significativo, diferente do visto inicialmente, com o valor de 0,2929, e o Breusch-Pagan teve valor n√£o significativo, assim como anteriormente, ou seja, abaixo de 0,05. Isso impactar√° apenas na vis√£o da hip√≥tese White, que testa se o modelo apresenta vari√¢ncias do termo de perturba√ß√£o n√£o iguais para todas as observa√ß√µes com as vari√°veis interligadas, descartando-a.
Por fim, para o teste RESET, feito anteriormente na quest√£o 9, que tinha dado um p-valor n√£o significativo, agora tem, sendo ele 0,1088, portanto n√£o podemos descartar sua hip√≥tese nula.

## Quest√£o 13
Fa√ßa an√°lise gr√°fica e estat√≠stica para presen√ßa de outliers.
```{r}
par(mfrow=c(2,2))
plot(reg4)
```
```{r}
par(mfrow=c(1,2))
hist(reg4$residuals)
a <- qqPlot(reg4)
```
Por essas analises, encontramos 3 possiveis outliers 32, 40, 49
## Quest√£o 14
Reestime o modelo excluindo os outliers e fa√ßa uma tabela comparativa dos modelos com e
sem outliers. Analise a robustez do modelo

Primeiro, fazendo uma fun√ß√£o para facilitar a analise da robustez:
```{r}
robustes <- function(data,reg, vector_area) {
  results <- matrix(,
    nrow = 10000,
    ncol = length(names(reg$coefficients)))
  name_coeficientes <- names(reg$coefficients)

  colnames(results) <- name_coeficientes
  for (i in 1:10000) {
    index_amostras <- sample(1:dim(data)[1],size= dim(data)[1], T)
    amostra <- data[index_amostras,]
    mod <- lm(log(Div) ~ BtM + RPLP + ROE + log(AtivoTotal), data = amostra)
    results[i,] <- mod$coefficients
  }
  par(mfrow = vector_area,
      mar = c(2, 2, 2, 2))
  name <- name_coeficientes[1]
  Hist <- hist(results[, name], plot = F, breaks = 100)
  plot(Hist, main = name, xlab = "", col = ifelse(Hist$breaks <= quantile(results[, name], 0.025), "red", ifelse(Hist$breaks >= quantile(results[, name], 0.975), "red", "white")),
       xlim = c(-9,-5))

  name <- name_coeficientes[2]
  Hist <- hist(results[, name], plot = F, breaks = 100)
  plot(Hist, main = name, xlab = "", col = ifelse(Hist$breaks <= quantile(results[, name], 0.025), "red", ifelse(Hist$breaks >= quantile(results[, name], 0.975), "red", "white")),
       xlim = c(-0.8,-0.2))

  name <- name_coeficientes[3]
  Hist <- hist(results[, name], plot = F, breaks = 100)
  plot(Hist, main = name, xlab = "", col = ifelse(Hist$breaks <= quantile(results[, name], 0.025), "red", ifelse(Hist$breaks >= quantile(results[, name], 0.975), "red", "white")),
       xlim = c(-1,2))

  name <- name_coeficientes[4]
  Hist <- hist(results[, name], plot = F, breaks = 100)
  plot(Hist, main = name, xlab = "", col = ifelse(Hist$breaks <= quantile(results[, name], 0.025), "red", ifelse(Hist$breaks >= quantile(results[, name], 0.975), "red", "white")),
       xlim = c(-0.6,0.6))

  name <- name_coeficientes[5]
  Hist <- hist(results[, name], plot = F, breaks = 100)
  plot(Hist, main = name, xlab = "", col = ifelse(Hist$breaks <= quantile(results[, name], 0.025), "red", ifelse(Hist$breaks >= quantile(results[, name], 0.975), "red", "white")),
       xlim = c(1,1.3))
}
```
```{r}
outliers <- c(32,40,49)
dataSemOutliers <- data[-outliers,]
reg4SemOutliers <- lm(log(Div) ~ BtM + RPLP + ROE + log(AtivoTotal), data = data[-outliers,])

robustes(data,reg4, c(3,2))
```
```{r}
robustes(dataSemOutliers,reg4, c(3,2))
```
Com os testes de robustez a maior descrepancia est√° no grafico RPLP, com outliers o desvio padr√£o dele foi maior do que o grafico sem outliers.
```{r}
stargazer(reg4,reg4SemOutliers,type="text",column.labels = c("Com Outliers", "Sem Outliers"))
```
As principais diferen√ßas foi a redu√ß√£o do desvio padr√£o dos residuos, entretanto impactou o R2 ajustado em 0.004 a mais, um valor relativamente baixo, sem uma mudan√ßa significativa nos coeficientes.